{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST data set with pure Convolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "haO2Ljo4Fvdx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,Activation,BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns \n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUXCpaUbHR5W"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRV0fWGPHRxe",
        "outputId": "60f25f79-619c-479c-8ef4-5fa18ccf5e96"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7bqA8J7IHAn",
        "outputId": "c0b36483-aff4-400f-8a38-c714140384dc"
      },
      "source": [
        "X_train = X_train.astype('float32')/255 #Scaling the data\n",
        "X_test = X_test.astype('float32')/255 \n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], '=train samples')\n",
        "print(X_test.shape[0], '=test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28)\n",
            "60000 =train samples\n",
            "10000 =test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ibJefFSIJ0W",
        "outputId": "c018d8ef-af6f-43cb-9117-753b6eb31157"
      },
      "source": [
        "num_classes = 10 \n",
        "# print first ten (integer-valued) training labels\n",
        "print('Integer-valued labels:')\n",
        "print(y_train[:10])\n",
        "\n",
        "# one-hot encode the labels\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# print first ten (one-hot) training labels\n",
        "print('One-hot labels:')\n",
        "print(y_train[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Integer-valued labels:\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "One-hot labels:\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RppqhIDpIP9G",
        "outputId": "59242908-caff-4efc-eeb2-1409bcb18b9b"
      },
      "source": [
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "print('input_shape: ', input_shape)\n",
        "print('x_train shape:', X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape:  (28, 28, 1)\n",
            "x_train shape: (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DMDs4mkITKu",
        "outputId": "e5cd3fa1-4cb1-496d-dc08-ba1b0d1926b5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=10,kernel_size=(3,3), activation='relu', input_shape=(28,28,1))) #26\n",
        "\n",
        "model.add(Conv2D(filters=10,kernel_size=(3,3), activation='relu'))  #24         \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(filters=10,kernel_size=(3,3), activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "\n",
        "model.add(Conv2D(filters=16,kernel_size=(3,3), activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(filters=10,kernel_size=(1,1), activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(filters=10,kernel_size=(3,3), activation='relu')) #7      \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        " \n",
        "model.add(Conv2D(filters=10,kernel_size=(3,3), activation='relu')) #5       \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=10,kernel_size=(5,5))) #1 \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 24, 24, 10)        910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 22, 22, 10)        910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 9, 9, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 5, 5, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,140\n",
            "Trainable params: 8,008\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRTPiiBSPd5a",
        "outputId": "2432b826-ab83-4faf-8477-78e3fe41ee76"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.003), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test, y_test),\n",
        "          callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.003.\n",
            "469/469 [==============================] - 5s 8ms/step - loss: 0.2271 - accuracy: 0.9286 - val_loss: 0.1337 - val_accuracy: 0.9596\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0773 - accuracy: 0.9761 - val_loss: 0.0508 - val_accuracy: 0.9824\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0348 - val_accuracy: 0.9878\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0527 - accuracy: 0.9836 - val_loss: 0.0355 - val_accuracy: 0.9882\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0461 - accuracy: 0.9850 - val_loss: 0.0273 - val_accuracy: 0.9909\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.0295 - val_accuracy: 0.9899\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.0240 - val_accuracy: 0.9915\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0245 - val_accuracy: 0.9915\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.0222 - val_accuracy: 0.9932\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0244 - val_accuracy: 0.9913\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0007159905.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.0253 - val_accuracy: 0.9914\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.000665336.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.0226 - val_accuracy: 0.9930\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0006213753.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0235 - val_accuracy: 0.9919\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0005828638.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0231 - val_accuracy: 0.9924\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0005488474.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0228 - val_accuracy: 0.9927\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0005185825.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.0199 - val_accuracy: 0.9936\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.000491481.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0194 - val_accuracy: 0.9931\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0004670715.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0216 - val_accuracy: 0.9925\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0004449718.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0212 - val_accuracy: 0.9929\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.000424869.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0199 - val_accuracy: 0.9935\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0004065041.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0201 - val_accuracy: 0.9927\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.000389661.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0194 - val_accuracy: 0.9931\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0003741581.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0190 - val_accuracy: 0.9934\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003598417.\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0003465804.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0177 - val_accuracy: 0.9939\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0003342618.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0179 - val_accuracy: 0.9943\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0003227889.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0003120774.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0197 - val_accuracy: 0.9930\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.000302054.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0185 - val_accuracy: 0.9941\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0002926544.\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0186 - val_accuracy: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4d044344d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VirMuHig7PW"
      },
      "source": [
        "Here i run for 30 epochs but in 25 epcohs i got validation accuracy as 99.40%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijXPg4hjhO8N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}